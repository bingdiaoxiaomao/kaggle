{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分中，将进行以下三个部分的工作：\n",
    "* 特征选择\n",
    "* 模型选择\n",
    "* 模型超参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 特征选择\n",
    "导入在上一节中已经提取到的特征数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../data/all_engineered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = all_data['SK_ID_CURR']\n",
    "Target = all_data['TARGET']\n",
    "all_data = all_data.drop(columns=['SK_ID_CURR','TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 880)\n"
     ]
    }
   ],
   "source": [
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过我们上一步的数据提取，已经得到一个包含880维特征的预测特征数据集，这些特征之间可能存在高度共线性，也可能存在缺失比例过高等情况，在后续的特征选择的过程中，我们都需要注重关注这些情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    704\n",
       "int64      176\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_data.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查一下，是否有ID类的组合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns that contain SK_ID_CURR\n",
      "There are 0 columns that contain SK_ID_BUREAU\n",
      "There are 0 columns that contain SK_ID_PREV\n"
     ]
    }
   ],
   "source": [
    "cols_with_id = [x for x in all_data.columns if 'SK_ID_CURR' in x]\n",
    "cols_with_bureau_id = [x for x in all_data.columns if 'SK_ID_BUREAU' in x]\n",
    "cols_with_previous_id = [x for x in all_data.columns if 'SK_ID_PREV' in x]\n",
    "print('There are {} columns that contain SK_ID_CURR'.format(len(cols_with_id)))\n",
    "print('There are {} columns that contain SK_ID_BUREAU'.format(len(cols_with_bureau_id)))\n",
    "print('There are {} columns that contain SK_ID_PREV'.format(len(cols_with_previous_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算特征之间的共线性，如果以完整数据集计算的话，会非常的耗时，因此，这里仅抽样了10000条数据，大致估计特征之间的线性相关性系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>PREVIOUS_AMT_APPLICATION_sum</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_min</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_mean</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_max</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_min</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_mean</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_max</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_min</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_mean</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764551</td>\n",
       "      <td>0.769956</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.096294</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.018063</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.036263</td>\n",
       "      <td>0.041752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>0.764551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986834</td>\n",
       "      <td>0.029969</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.058421</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.059139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.154765</td>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.156607</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.022591</td>\n",
       "      <td>0.145764</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.155529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>0.769956</td>\n",
       "      <td>0.986834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.060406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106582</td>\n",
       "      <td>0.155953</td>\n",
       "      <td>0.156884</td>\n",
       "      <td>0.157626</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.165286</td>\n",
       "      <td>0.170091</td>\n",
       "      <td>0.174647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.029969</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.083174</td>\n",
       "      <td>0.082776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186542</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.339726</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.035344</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.051534</td>\n",
       "      <td>0.052309</td>\n",
       "      <td>0.052995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  \\\n",
       "AMT_ANNUITY                   1.000000    0.764551         0.769956   \n",
       "AMT_CREDIT                    0.764551    1.000000         0.986834   \n",
       "AMT_GOODS_PRICE               0.769956    0.986834         1.000000   \n",
       "AMT_INCOME_TOTAL              0.036592    0.029969         0.029258   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY     0.002343    0.003697         0.004279   \n",
       "\n",
       "                           AMT_INCOME_TOTAL  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "AMT_ANNUITY                        0.036592                   0.002343   \n",
       "AMT_CREDIT                         0.029969                   0.003697   \n",
       "AMT_GOODS_PRICE                    0.029258                   0.004279   \n",
       "AMT_INCOME_TOTAL                   1.000000                   0.000072   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY          0.000072                   1.000000   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "AMT_ANNUITY                                  0.014115   \n",
       "AMT_CREDIT                                   0.004921   \n",
       "AMT_GOODS_PRICE                              0.005165   \n",
       "AMT_INCOME_TOTAL                             0.001299   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.186542   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "AMT_ANNUITY                                 0.025148   \n",
       "AMT_CREDIT                                  0.058421   \n",
       "AMT_GOODS_PRICE                             0.061678   \n",
       "AMT_INCOME_TOTAL                            0.001082   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                   0.006920   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "AMT_ANNUITY                                 0.014171   \n",
       "AMT_CREDIT                                  0.006255   \n",
       "AMT_GOODS_PRICE                             0.004264   \n",
       "AMT_INCOME_TOTAL                            0.004360   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                   0.011064   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "AMT_ANNUITY                                  0.004642   \n",
       "AMT_CREDIT                                   0.007055   \n",
       "AMT_GOODS_PRICE                              0.006369   \n",
       "AMT_INCOME_TOTAL                             0.001336   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.339726   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
       "AMT_ANNUITY                                  0.023894   \n",
       "AMT_CREDIT                                   0.059139   \n",
       "AMT_GOODS_PRICE                              0.060406   \n",
       "AMT_INCOME_TOTAL                             0.002897   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.021164   \n",
       "\n",
       "                                           ...                    \\\n",
       "AMT_ANNUITY                                ...                     \n",
       "AMT_CREDIT                                 ...                     \n",
       "AMT_GOODS_PRICE                            ...                     \n",
       "AMT_INCOME_TOTAL                           ...                     \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                  ...                     \n",
       "\n",
       "                           PREVIOUS_AMT_APPLICATION_sum  \\\n",
       "AMT_ANNUITY                                    0.110532   \n",
       "AMT_CREDIT                                     0.104095   \n",
       "AMT_GOODS_PRICE                                0.106582   \n",
       "AMT_INCOME_TOTAL                               0.012086   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                      0.007431   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_min  \\\n",
       "AMT_ANNUITY                                       0.095331   \n",
       "AMT_CREDIT                                        0.154765   \n",
       "AMT_GOODS_PRICE                                   0.155953   \n",
       "AMT_INCOME_TOTAL                                  0.018548   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                         0.021395   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_mean  \\\n",
       "AMT_ANNUITY                                        0.095870   \n",
       "AMT_CREDIT                                         0.155780   \n",
       "AMT_GOODS_PRICE                                    0.156884   \n",
       "AMT_INCOME_TOTAL                                   0.018949   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                          0.021305   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_max  \\\n",
       "AMT_ANNUITY                                       0.096294   \n",
       "AMT_CREDIT                                        0.156607   \n",
       "AMT_GOODS_PRICE                                   0.157626   \n",
       "AMT_INCOME_TOTAL                                  0.019328   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                         0.021185   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_min  \\\n",
       "AMT_ANNUITY                                          0.016282   \n",
       "AMT_CREDIT                                           0.019407   \n",
       "AMT_GOODS_PRICE                                      0.011076   \n",
       "AMT_INCOME_TOTAL                                     0.003224   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                            0.035135   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_mean  \\\n",
       "AMT_ANNUITY                                           0.018063   \n",
       "AMT_CREDIT                                            0.021000   \n",
       "AMT_GOODS_PRICE                                       0.012617   \n",
       "AMT_INCOME_TOTAL                                      0.003098   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                             0.035344   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_max  \\\n",
       "AMT_ANNUITY                                          0.019842   \n",
       "AMT_CREDIT                                           0.022591   \n",
       "AMT_GOODS_PRICE                                      0.014157   \n",
       "AMT_INCOME_TOTAL                                     0.002972   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                            0.035549   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_min  \\\n",
       "AMT_ANNUITY                                             0.030728   \n",
       "AMT_CREDIT                                              0.145764   \n",
       "AMT_GOODS_PRICE                                         0.165286   \n",
       "AMT_INCOME_TOTAL                                        0.083446   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                               0.051534   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_mean  \\\n",
       "AMT_ANNUITY                                              0.036263   \n",
       "AMT_CREDIT                                               0.150757   \n",
       "AMT_GOODS_PRICE                                          0.170091   \n",
       "AMT_INCOME_TOTAL                                         0.083174   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                                0.052309   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_max  \n",
       "AMT_ANNUITY                                             0.041752  \n",
       "AMT_CREDIT                                              0.155529  \n",
       "AMT_GOODS_PRICE                                         0.174647  \n",
       "AMT_INCOME_TOTAL                                        0.082776  \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                               0.052995  \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "corr_matrix = all_data.sample(10000).corr().abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>PREVIOUS_AMT_APPLICATION_sum</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_min</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_mean</th>\n",
       "      <th>PREVIOUS_DAYS_FIRST_DRAWING_max</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_min</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_mean</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIMARY_max</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_min</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_mean</th>\n",
       "      <th>PREVIOUS_RATE_INTEREST_PRIVILEGED_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764551</td>\n",
       "      <td>0.769956</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.096294</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.018063</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.036263</td>\n",
       "      <td>0.041752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986834</td>\n",
       "      <td>0.029969</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.058421</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.059139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.154765</td>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.156607</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.022591</td>\n",
       "      <td>0.145764</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>0.155529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.060406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106582</td>\n",
       "      <td>0.155953</td>\n",
       "      <td>0.156884</td>\n",
       "      <td>0.157626</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.165286</td>\n",
       "      <td>0.170091</td>\n",
       "      <td>0.174647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.083174</td>\n",
       "      <td>0.082776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186542</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.339726</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.021395</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.035344</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.051534</td>\n",
       "      <td>0.052309</td>\n",
       "      <td>0.052995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  \\\n",
       "AMT_ANNUITY                        NaN    0.764551         0.769956   \n",
       "AMT_CREDIT                         NaN         NaN         0.986834   \n",
       "AMT_GOODS_PRICE                    NaN         NaN              NaN   \n",
       "AMT_INCOME_TOTAL                   NaN         NaN              NaN   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY          NaN         NaN              NaN   \n",
       "\n",
       "                           AMT_INCOME_TOTAL  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "AMT_ANNUITY                        0.036592                   0.002343   \n",
       "AMT_CREDIT                         0.029969                   0.003697   \n",
       "AMT_GOODS_PRICE                    0.029258                   0.004279   \n",
       "AMT_INCOME_TOTAL                        NaN                   0.000072   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY               NaN                        NaN   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "AMT_ANNUITY                                  0.014115   \n",
       "AMT_CREDIT                                   0.004921   \n",
       "AMT_GOODS_PRICE                              0.005165   \n",
       "AMT_INCOME_TOTAL                             0.001299   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.186542   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "AMT_ANNUITY                                 0.025148   \n",
       "AMT_CREDIT                                  0.058421   \n",
       "AMT_GOODS_PRICE                             0.061678   \n",
       "AMT_INCOME_TOTAL                            0.001082   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                   0.006920   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "AMT_ANNUITY                                 0.014171   \n",
       "AMT_CREDIT                                  0.006255   \n",
       "AMT_GOODS_PRICE                             0.004264   \n",
       "AMT_INCOME_TOTAL                            0.004360   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                   0.011064   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "AMT_ANNUITY                                  0.004642   \n",
       "AMT_CREDIT                                   0.007055   \n",
       "AMT_GOODS_PRICE                              0.006369   \n",
       "AMT_INCOME_TOTAL                             0.001336   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.339726   \n",
       "\n",
       "                           AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
       "AMT_ANNUITY                                  0.023894   \n",
       "AMT_CREDIT                                   0.059139   \n",
       "AMT_GOODS_PRICE                              0.060406   \n",
       "AMT_INCOME_TOTAL                             0.002897   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                    0.021164   \n",
       "\n",
       "                                           ...                    \\\n",
       "AMT_ANNUITY                                ...                     \n",
       "AMT_CREDIT                                 ...                     \n",
       "AMT_GOODS_PRICE                            ...                     \n",
       "AMT_INCOME_TOTAL                           ...                     \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                  ...                     \n",
       "\n",
       "                           PREVIOUS_AMT_APPLICATION_sum  \\\n",
       "AMT_ANNUITY                                    0.110532   \n",
       "AMT_CREDIT                                     0.104095   \n",
       "AMT_GOODS_PRICE                                0.106582   \n",
       "AMT_INCOME_TOTAL                               0.012086   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                      0.007431   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_min  \\\n",
       "AMT_ANNUITY                                       0.095331   \n",
       "AMT_CREDIT                                        0.154765   \n",
       "AMT_GOODS_PRICE                                   0.155953   \n",
       "AMT_INCOME_TOTAL                                  0.018548   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                         0.021395   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_mean  \\\n",
       "AMT_ANNUITY                                        0.095870   \n",
       "AMT_CREDIT                                         0.155780   \n",
       "AMT_GOODS_PRICE                                    0.156884   \n",
       "AMT_INCOME_TOTAL                                   0.018949   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                          0.021305   \n",
       "\n",
       "                           PREVIOUS_DAYS_FIRST_DRAWING_max  \\\n",
       "AMT_ANNUITY                                       0.096294   \n",
       "AMT_CREDIT                                        0.156607   \n",
       "AMT_GOODS_PRICE                                   0.157626   \n",
       "AMT_INCOME_TOTAL                                  0.019328   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                         0.021185   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_min  \\\n",
       "AMT_ANNUITY                                          0.016282   \n",
       "AMT_CREDIT                                           0.019407   \n",
       "AMT_GOODS_PRICE                                      0.011076   \n",
       "AMT_INCOME_TOTAL                                     0.003224   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                            0.035135   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_mean  \\\n",
       "AMT_ANNUITY                                           0.018063   \n",
       "AMT_CREDIT                                            0.021000   \n",
       "AMT_GOODS_PRICE                                       0.012617   \n",
       "AMT_INCOME_TOTAL                                      0.003098   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                             0.035344   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIMARY_max  \\\n",
       "AMT_ANNUITY                                          0.019842   \n",
       "AMT_CREDIT                                           0.022591   \n",
       "AMT_GOODS_PRICE                                      0.014157   \n",
       "AMT_INCOME_TOTAL                                     0.002972   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                            0.035549   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_min  \\\n",
       "AMT_ANNUITY                                             0.030728   \n",
       "AMT_CREDIT                                              0.145764   \n",
       "AMT_GOODS_PRICE                                         0.165286   \n",
       "AMT_INCOME_TOTAL                                        0.083446   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                               0.051534   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_mean  \\\n",
       "AMT_ANNUITY                                              0.036263   \n",
       "AMT_CREDIT                                               0.150757   \n",
       "AMT_GOODS_PRICE                                          0.170091   \n",
       "AMT_INCOME_TOTAL                                         0.083174   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                                0.052309   \n",
       "\n",
       "                           PREVIOUS_RATE_INTEREST_PRIVILEGED_max  \n",
       "AMT_ANNUITY                                             0.041752  \n",
       "AMT_CREDIT                                              0.155529  \n",
       "AMT_GOODS_PRICE                                         0.174647  \n",
       "AMT_INCOME_TOTAL                                        0.082776  \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                               0.052995  \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 184 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "to_drop = [column for column in upper.columns if any(upper[column]>threshold)]\n",
    "print('There are {} columns to remove.'.format(len(to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从1000条样本的估计结果来看，有186组特征之间存在着高于90%的线性相关性。这些两两的特征组合中，需求删除其中一个，仅留下其中一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data shape: (356255, 696)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.drop(columns=to_drop)\n",
    "print('all_data shape: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除缺失率高于60%的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREVIOUS_RATE_INTEREST_PRIVILEGED_min    0.983941\n",
       "COMMONAREA_AVG                           0.697141\n",
       "NONLIVINGAPARTMENTS_AVG                  0.692933\n",
       "FLOORSMIN_AVG                            0.676785\n",
       "BUREAU_LOAN_RATE_min                     0.669316\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_missing = (all_data.isnull().sum() / len(all_data)).sort_values(ascending = False)\n",
    "data_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_missing = data_missing.index[data_missing > 0.60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 columns with more than 60% missing values\n"
     ]
    }
   ],
   "source": [
    "data_missing = list(data_missing)\n",
    "print('There are {} columns with more than 60% missing values'.format(len(data_missing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set full shape: (356255, 596)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.drop(columns=data_missing)\n",
    "print('Data set full shape: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过这样简单的特征选择之后，最终的预测特征还有592维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_ratios = all_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(miss_ratios.values*100,bins=20)\n",
    "plt.xlabel('Missing ratio (%)')\n",
    "plt.ylabel('# count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    410\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes[miss_ratios>0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仍然存在缺失情况的特征有406维，不过从上图中也看到，大部分的数据缺失比例已经不高了，控制在了15%以内。现阶段，我们采取以0填补缺失值的方式，有时间的话可以做更加细致的分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3311"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征归一化\n",
    "将预测变量的范围都归一化到[0,1]之间，对于一些对特征大小敏感的算法，这样可以使得各个特征权重在同一个水平，更容易找到好的模型解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "受限于电脑内存，不能调用sklearn的MinMaxScaler的函数，自己编写了一个循环体也能执行同样的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [00:30<00:00, 19.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(feature_names):\n",
    "    all_data[col] = (all_data[col]-all_data[col].min())/(all_data[col].max()-all_data[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将预测变量重新分割为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = all_data[Target.notnull()]\n",
    "x_test = all_data[Target.isnull()]\n",
    "y_train = Target[Target.notnull()]\n",
    "y_test = Target[Target.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 596)\n",
      "(48744, 596)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_data, Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单模型 1: Logisti Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold交叉验证法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "lr_fit = LogisticRegression(C=1e-3,class_weight='balanced',penalty='l2',random_state=1,solver='sag',max_iter=1000,n_jobs=2)\n",
    "lr_cv = cross_val_score(estimator=lr_fit,X=x_train,y=y_train,cv=5,scoring='roc_auc',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574407575047764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold交叉验证的结果，逻辑回归的验证集AUC均值为0.757。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 贝叶斯优化逻辑回归的超参数C的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_evaluate(C=1e-4):\n",
    "    lr_fit = LogisticRegression(C=C,class_weight='balanced',penalty='l2',solver='sag',random_state=1,max_iter=1000,n_jobs=2)\n",
    "    return (cross_val_score(estimator=lr_fit,X=x_train,y=y_train,cv=5,scoring='roc_auc',verbose=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_BO = BayesianOptimization(f=lr_evaluate,pbounds={'C':[1e-4,1e-1]},verbose=1)\n",
    "lr_BO.maximize(init_points=3,n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算资源有限，这里不继续演示后续优化的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = LogisticRegression(C=0.0551,class_weight='balanced',penalty='l2',random_state=1,solver='sag',max_iter=1000,n_jobs=2)\n",
    "lr_fit.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_train = lr_fit.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,_ = roc_curve(y_true=y_train,y_score=lr_pred_train)\n",
    "auc_score = roc_auc_score(y_true=y_train,y_score=lr_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(fpr,tpr,linewidth=2,label='lr_roc_curve')\n",
    "plt.plot([0,1],[0,1],'k--',linewidth=2)\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel('False Prositive Rate(%) FPR')\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('True Prositive Rate(%) TPR')\n",
    "plt.title(\"Training AUC Score = {:.4f} by Logistic Regression\".format(auc_score))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr_fit.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "display(submit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_submit = submit.copy()\n",
    "lr_submit['TARGET'] = lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_submit.to_csv(\"../data/lr_submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "public score: 0.758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_names = x_train.columns.tolist()\n",
    "categorical_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain = lgb.Dataset(data=x_train.values,label=y_train.values,free_raw_data=False)\n",
    "train_X,valid_X,train_y,valid_y = train_test_split(x_train,y_train,stratify=y_train,random_state=2018)\n",
    "dtrain = lgb.Dataset(data=train_X.values,label=train_y.values,feature_name=predictor_names,categorical_feature=None,free_raw_data=False)\n",
    "dvalid = lgb.Dataset(data=valid_X.values,label=valid_y.values,feature_name=predictor_names,categorical_feature=None,free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_evaluate_cv(colsample_bytree=0.7,\n",
    "                    learning_rate=0.1,num_leaves=32,\n",
    "                    subsample=0.9,reg_alpha=0.0,\n",
    "                    reg_lambda=0.0,min_child_weight=0.0):\n",
    "    params = dict()\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree,1),0)\n",
    "    params['learning_rate'] = max(min(learning_rate,1),0)\n",
    "    params['num_leaves'] = int(num_leaves)\n",
    "    params['subsample'] = max(min(subsample,1),0)\n",
    "    params['reg_alpha'] = max(0,reg_alpha)\n",
    "    params['reg_lambda'] = max(0,reg_lambda)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['is_unbalance'] = True\n",
    "    params['categorical_features'] = categorical_features\n",
    "    params['predictor'] = predictor_names\n",
    "    params['objective'] = 'binary'\n",
    "    cv_result =  lgb.cv(params=params,train_set=Dtrain,\n",
    "                        early_stopping_rounds=50,\n",
    "                        metrics='auc',nfold=3,\n",
    "                        num_boost_round=2000,\n",
    "                        verbose_eval=False,seed=1,show_stdv=True)                       \n",
    "    return cv_result['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义贝叶斯优化lightgbm的超参数及优化范围，作为示例，仅优化colsample_bytree和subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_evaluate_cv,\n",
    "                             pbounds={'colsample_bytree':(0.5,0.7),\n",
    "                                      'learning_rate':(0.1,0.1),\n",
    "                                      'num_leaves':(31,31),\n",
    "                                      'subsample':(0.5,0.95),\n",
    "                                      'reg_alpha':(0.1,0.1),\n",
    "                                      'reg_lambda':(0.1,0.1),\n",
    "                                      'min_child_weight':(1,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO.maximize(init_points=3,n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO.res['max']['max_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以最优超参数训练lgb模型，并输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
